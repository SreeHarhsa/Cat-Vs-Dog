{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the necessary libraries\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_DyUfCTgdwa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of base directory: ['train', 'validation']\n",
      "\n",
      "Contents of train directory: ['cats', 'dogs']\n",
      "\n",
      "Contents of validation directory: ['cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = 'cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join(BASE_DIR, 'train')\n",
    "validation_dir = os.path.join(BASE_DIR, 'validation')\n",
    "\n",
    "# Directory with training cat/dog pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with validation cat/dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "print(f\"Contents of base directory: {os.listdir(BASE_DIR)}\")\n",
    "\n",
    "print(f\"\\nContents of train directory: {os.listdir(train_dir)}\")\n",
    "\n",
    "print(f\"\\nContents of validation directory: {os.listdir(validation_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uWllK_Wad-Mx"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    '''Creates a CNN with 4 convolutional layers'''\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.Input(shape=(150, 150, 3)),\n",
    "        tf.keras.layers.Rescaling(1./255),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3sj3ERldRGpY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the training dataset\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    label_mode='binary'\n",
    "    )\n",
    "\n",
    "# Instantiate the validation dataset\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    label_mode='binary'\n",
    "    )\n",
    "\n",
    "# Optimize the datasets for training\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset_final = (train_dataset\n",
    "                       .cache()\n",
    "                       .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                       .prefetch(PREFETCH_BUFFER_SIZE)\n",
    "                       )\n",
    "\n",
    "validation_dataset_final = (validation_dataset\n",
    "                            .cache()\n",
    "                            .prefetch(PREFETCH_BUFFER_SIZE)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdqUoF44esR3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# Constant for epochs\n",
    "EPOCHS = 20\n",
    "\n",
    "# Create a new model\n",
    "model = create_model()\n",
    "\n",
    "# Setup the training parameters\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "      train_dataset_final,\n",
    "      epochs=EPOCHS,\n",
    "      validation_data=validation_dataset_final,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZWPcmKWO303"
   },
   "outputs": [],
   "source": [
    "def plot_loss_acc(history):\n",
    "    '''Plots the training and validation loss and accuracy from a history object'''\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "    ax[0].plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "    ax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    ax[0].set_title('Training and validation accuracy')\n",
    "    ax[0].set_xlabel('epochs')\n",
    "    ax[0].set_ylabel('accuracy')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(epochs, loss, 'bo', label='Training Loss')\n",
    "    ax[1].plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "    ax[1].set_title('Training and validation loss')\n",
    "    ax[1].set_xlabel('epochs')\n",
    "    ax[1].set_ylabel('loss')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vojz4NYXiT_f"
   },
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUv0b0TCRzJN"
   },
   "outputs": [],
   "source": [
    "# Define fill mode.\n",
    "FILL_MODE = 'nearest'\n",
    "\n",
    "# Create the augmentation model.\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    # Specify the input shape.\n",
    "    tf.keras.Input(shape=(150,150,3)),\n",
    "    # Add the augmentation layers\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2, fill_mode=FILL_MODE),\n",
    "    tf.keras.layers.RandomTranslation(0.2,0.2, fill_mode=FILL_MODE),\n",
    "    tf.keras.layers.RandomZoom(0.2, fill_mode=FILL_MODE)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0Q9C8hP4P6O"
   },
   "outputs": [],
   "source": [
    "def demo_augmentation(sample_image, model, num_aug):\n",
    "    '''Takes a single image array, then uses a model to generate num_aug transformations'''\n",
    "\n",
    "    # Instantiate preview list\n",
    "    image_preview = []\n",
    "\n",
    "    # Convert input image to a PIL image instance\n",
    "    sample_image_pil = tf.keras.utils.array_to_img(sample_image)\n",
    "\n",
    "    # Append the result to the list\n",
    "    image_preview.append(sample_image_pil)\n",
    "\n",
    "    # Apply the image augmentation and append the results to the list\n",
    "    for i in range(NUM_AUG):\n",
    "        sample_image_aug = model(tf.expand_dims(sample_image, axis=0))\n",
    "        sample_image_aug_pil = tf.keras.utils.array_to_img(tf.squeeze(sample_image_aug))\n",
    "        image_preview.append(sample_image_aug_pil)\n",
    "\n",
    "    # Instantiate a subplot\n",
    "    fig, axes = plt.subplots(1, NUM_AUG + 1, figsize=(12, 12))\n",
    "\n",
    "    # Preview the images.\n",
    "    for index, ax in enumerate(axes):\n",
    "        ax.imshow(image_preview[index])\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        if index == 0:\n",
    "            ax.set_title('original')\n",
    "        else:\n",
    "            ax.set_title(f'augment {index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ap0OnQKfX0MI"
   },
   "outputs": [],
   "source": [
    "# Get a batch of images\n",
    "sample_batch = list(train_dataset.take(1))[0][0]\n",
    "print(f'images per batch: {len(sample_batch)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBIbpv7GXX-h"
   },
   "outputs": [],
   "source": [
    "NUM_AUG = 4\n",
    "\n",
    "# Apply the transformations to the first 4 images\n",
    "demo_augmentation(sample_batch[0], data_augmentation, NUM_AUG)\n",
    "demo_augmentation(sample_batch[1], data_augmentation, NUM_AUG)\n",
    "demo_augmentation(sample_batch[2], data_augmentation, NUM_AUG)\n",
    "demo_augmentation(sample_batch[3], data_augmentation, NUM_AUG)\n",
    "\n",
    "# Uncomment the line below to delete the variable to free up some memory\n",
    "# del sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXVW2NzMkW_i"
   },
   "outputs": [],
   "source": [
    "# Instantiate the base model\n",
    "model_without_aug = create_model()\n",
    "\n",
    "# Prepend the data augmentation layers to the base model\n",
    "model_with_aug = tf.keras.models.Sequential([\n",
    "    data_augmentation,\n",
    "    model_without_aug\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_with_aug.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UK7_Fflgv8YC"
   },
   "outputs": [],
   "source": [
    "EPOCHS=80\n",
    "\n",
    "# Train the new model\n",
    "history_with_aug = model_with_aug.fit(\n",
    "      train_dataset_final,\n",
    "      epochs=EPOCHS,\n",
    "      validation_data=validation_dataset_final,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnyRnwopT5aW"
   },
   "outputs": [],
   "source": [
    "# Plot the results of training with data augmentation\n",
    "plot_loss_acc(history_with_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown the kernel to free up resources. \n",
    "# Note: You can expect a pop-up when you run this cell. You can safely ignore that and just press `Ok`.\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "k = get_ipython().kernel\n",
    "\n",
    "k.do_shutdown(restart=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
